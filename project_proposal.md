# Junior Seminar (CMPSC 580) Project Proposal

## Semester: Spring 2024

## GitHub Handle: audreyblarr

## Name: Audrey Blarr

## Major: INFM

## Project Title: Reliability Score - A Quick Reliability Evaluation of Web-Derived Articles

---

## Introduction

In a research world full of unnecessary biases and the detrimental spread of inaccurate and outdated information, compiling a list of resources to utilize in research studies while trusting they’re 100% accurate can pose many difficulties. In recent times, where the spread of information online is extremely vast, it can be easy for young researchers especially to label information they come across as factual without feeling obligated to do further, more intricate research into where exactly this information is being derived from. It’s also crucial for researchers to know which elements of a research article should be analyzed to determine the overall accuracy and relevancy of the information, which isn’t exactly common knowledge. This proposed project aims to create a database in which young researchers can take any research article’s URL and pass it through a system to derive a list of crucial information about the article, including the number of contributors to the article, the education levels of said contributors, the date of publication, the amount of updates made to the information and when they occurred, and any other elements necessary in determining reliability. As the values of the article’s elements are produced, they will be mapped to a specific “reliability score” to provide a clear and concise answer to the researcher as to whether or not this article should be considered as factual in their own research study. The goal of this project is to determine which elements of a research article should be taken into consideration while evaluating reliability of the provided information, and how exactly those elements’ values can be mapped to a concise reliability score. Opportunities will also be posed in which the database’s ability to create an accurate scoring of any research article can be tested, and any changes necessary to improve the accuracy of this system will be stated as means of future research and implementation.

## Related Work

A large issue causing researchers to use unreliable information in their own studies is a lack of knowledge in determining how exactly to spot an inaccurate source, especially if the researcher is young and/or less experienced. There’s the more obvious division of sources into primary and secondary sources, with primary, first-hand evidence being more reliable out of the two, yet there are many other distinctions that exist to aid in evaluating a source. When evaluating web sources in particular, the domain extension on the URL is the first place to look. Educational resources, arguably the most reliable in academic settings, end with ‘.edu’, while organizations end with ‘.org’, and government-related websites end in ‘.gov’. Web sources ending in ‘.com’ might impact the reliability of the source because they’re derived from websites with a commercial aspect. Additionally, there is a quick way to evaluate the reliability of a source through performing the CRAAP test. This criteria takes a look at how current the data is, how relevant it is to your own research, if the author and publisher have authority on the topic in question, accuracy of author citations, and the purpose behind its publication [1]. To evaluate the source in question, this coded system will determine the domain extension of the URL, provide links to author and publisher information for reader education purposes, and also take into account the publication date and whether or not the article has been updated since then. Each of these resource components will either increase or decrease the value of the article’s reliability score, depending on how it may influence the accuracy of the data within.

To correctly analyze a source’s elements, such as the author, publisher, and publication dates, a system must be developed to extract these specific components directly from the article. Python supports a library called BeautifulSoup, which works with a parser to extract data from a resource to further navigate, search, and modify the parse tree. Passing an HTML or XML file through the BeautifulSoup constructor converts the source to Unicode, and the HTML entities into Unicode characters [2]. Once BeautifulSoup extracts and compiles key elements of the source, given that these elements are requested from the URL using the ‘requests’ module, JSON can be utilized to arrange the extractions into human-readable data structures that are easy to work with, comparable to dictionaries. 

The Free Code Camp organization provides methods on how to efficiently scrape data from the web using Python coding. This process relies on sending HTTP requests, returning a Response Object, by incorporating the Python module ‘requests’. Then, several ‘soup’ functions are utilized to extract and store specific elements from the article, including the title, head, and body of the article [5]. Obtaining the values of these elements, as well as others returned within the JSON code, will allow for a quick and easy analysis of each component to the article, one value at a time. The utilization of data structures and variables to store these values is crucial for allowing these elements to be referenced later while analyzing how each value impacts the reliability of the overall article. 

The data extraction process is reliant on four main steps. From the web browser, identifying the author and affiliation data needing to be scraped is a crucial first step. Next, a framework such as BeautifulSoup must be utilized to simplify the task of sending requests to the web page, parsing through the JSON response, and extracting the author elements. The data extracted must be stored in a file for later reference to make the analysis process more efficient. The above steps should be repeated as a last step to analyze the script’s efficiency with other sources and formats [3]. These steps will be performed throughout the provided script to accurately and efficiently derive author and publisher information from given sources, and store these values to reference in processes of analysis.
JSON can be complicated to work with in the beginning, but it pays off as the data becomes much more readable and efficient in storing important information on an article. JSON ‘object’ is very comparable to a Python dictionary. After a computing system encounters a large amount of data, the dumps() method is crucial in writing the data into a Python string for easy access, and an ‘indent’ argument within this method changes the whitespace of the Python string, which allows it to read as a dictionary typically would. JSON’s loads() method turns JSON encoded data into Python objects, and is especially useful when the JSON data is derived from an external source [4]. 

## Prototype

As mentioned above, this project’s prototype utilizes Python modules BeautifulSoup, requests, and JSON to derive and organize elements of an external source given a URL argument. The script first prompts the user to copy and paste the URL in question, stored under a ‘url’ variable. Next, the ‘soup’ variable is comprised of the result of using the BeautifulSoup method, with the first argument utilizing the requests.get() function on ‘url’ for its contents, and the second argument includes the ‘html.parser’ to properly parse through the data. The soup.select_one() function then derives the contents of the soup, then passes it through the json.loads() module to turn the data into Python objects for a more efficient and human-readable extraction, stored under the ‘data’ variable. From the ‘data’ and ‘soup’ variables, the prototype extracts crucial information for analysis, including the title of the article (soup.title.text), the author (data[“author”][“name”]), the author’s own URL (data[“author”][“url”]), the type of publisher (data[“publisher”][“@type”]), the date of publication (data[“datePublished”]), the date of modification (data[“dateModified”]), the publisher (data[“publisher”][“name”]), and the publisher’s own URL (data[“publisher”][“url”]). The reliability score of any article passed through begins with a 50, as established within the prototype, and this score will increase and/or decrease depending on the values derived. For example, the domain of the URL itself will factor into the score, with ‘.com’ decreasing the reliability due to the commercial aspect of the source, while ‘.edu’ increases the reliability as it’s a publisher associated with educational purposes. Furthermore, the date of publication of the article is compared to the date of modification, increasing the reliability if the dates aren’t equal (signifying a more recent implementation of the research to increase accuracy/relevance), and decreasing the reliability if the provided dates are the same, meaning the article hasn’t been updated since being published. In addition to the reliability score, links are provided for the user to do their own research and educate themselves on the author and publisher, as well as any other work they’ve contributed to. As the final score is provided, there is an encouragement of the user to conduct their own research into the reliability, as this system only provides a quick and easy assessment. 

## Preliminary Results and Outcomes

To test the accuracy of this prototype, the URL of a crucial article used to research and implement the methods of this project will be passed through as the argument of the Python script. The URL is presented as the following: “https://www.freecodecamp.org/news/web-scraping-python-tutorial-how-to-scrape-data-from-a-website/”. The URL is passed into the BeautifulSoup method, the arguments consisting of the requests.get().contents function, and the ‘html.parser’ being used to parse the data. After the ‘soup’ is created, the json.loads() method is used, the argument incorporating the soup.select_one().contents function, selecting the data with type= ‘application/ld+json’ from the soup. This becomes the extracted data that the rest of the analysis will rely on. The user is informed of the initial reliability score being a 50, as to provide an unbiased midpoint subject to an increase and/or a decrease in number. The script then extracts the title of the article (“Web Scraping Python Tutorial - How to Scrape Data From a Website”) using soup.title.text, and the author (Mehul Mohan) using data[“author”][“name]. A link to the author’s information page is provided using data[“author”][“url], a clickable link for the user to further research the author for their reliability and other work. Next, the script informs the user of the website type using data[“publisher”][“@type”], this example being an Organization website. Because the URL contains “.org” as the domain name, the score increases by 15 points as its association with an organization increases its reliability compared to other domain options. With a score now equating 65, the article’s date of publication is provided using data[“datePublished”], while the date of modification is provided using data[“dateModified”]. In this instance, the date of modification (2020-10-26T23:54:33.000Z) differs from the date of publication (2020-09-25T20:24:10.000Z), implying that the article has implemented updates since its publication. Since this increases the reliability of the article, the script adds 20 points to the score, now equating an 85. The publisher of the article is provided to the user through data[“publisher”][“name”], as well as a link leading to more information about the publisher (data[“publisher”][“url”]). That way, the user can do their own research on the publisher to evaluate its accuracy further than just analyzing the domain of the article URL. As the final score is stated to the user, an 85, they are then encouraged to do their own research into the article’s elements that aren’t analyzed within this program so they don’t accidentally include unreliable information within their own research. The output to this prototype, given this example URL, is as follows:

```Python
!!! Each article begins with a 50 percent reliability score, as we view the source from an unbiased standpoint. !!!

The article in question is titled "Web Scraping Python Tutorial – How to Scrape Data From A Website", written by Mehul Mohan.
Read more about Mehul Mohan and their other work to determine their reliability: https://www.freecodecamp.org/news/author/mehulmpt/

This website is a(n) Organization!
Since your article is derived from a website associated with an organization, its score is now a 65.

Date of publication: 2020-09-25T20:24:10.000Z
Date of modification: 2020-10-26T23:54:33.000Z
Because your article has been updated since its publication, your reliability score is now a 85.

The publisher of your article is freeCodeCamp.org. Read more about this publisher here to determine their reliability: https://www.freecodecamp.org/news/.

Through a quick analysis of your article in question, the reliability score is determined to be a 85. However, it's important to follow through with research of your own, both on the author(s) and the publisher, to fully determine whether or not the information presented is trustworthy to use in further research.
```

## Conclusion/Future Work

The prototype of this project determined the article in question, "Web Scraping Python Tutorial – How to Scrape Data From A Website", to be a reliable source, as the final score is an 85. Knowing this article is very reliable because it provided accurate information on how to implement the methods and research within this project, it’s a very good sign that it achieved a good reliability score. This prototype is a great method of providing a quick and easy assessment of the reliability of this article without the user having to derive the article’s elements and links about the author/publisher themselves, yet it’s still encouraged for the user to conduct their own research to fact-check this system. As young researchers aren’t prone to doing any research regarding the reliability of their potential articles for research, this provides a baseline for users to see the elements of the article in question, as well as an estimated reliability score, all in one place. 

There are many tasks needing to be done to perfect this prototype and ensure an accurate result to the user, no matter the article used. Some trouble was posed if the data derived from the URL in question was missing some crucial information about its article’s elements, causing the program to crash and not return anything. It’s important that changes to this prototype are implemented to be more inclusive of any article the user may come across, regardless of how much information is provided within the source. Furthermore, more information about the author and the publisher, such as the author’s title and educational background, and the publisher’s ranking amongst others, should be derived from the article and taken into consideration while calculating the reliability score. Lastly, the output that the script produces could be a lot more visually appealing, such as incorporating bold letters, graphics, color-coding, and perhaps even a web page presenting the data to ensure the crucial information derived through evaluation is emphasized and easy to read. Also, once the script can include more articles to evaluate, more experiments should be conducted to test the accuracy, efficiency, and reliability of the score calculations created. Through implementing these changes, the horizons of this project will be broadened to include any article in question and make the program much more user-friendly.

## References

[1] George, T. (2021, August 26). What Are Credible Sources & How to Spot Them | Examples. Scribbr. Retrieved May 3, 2024, from https://www.scribbr.com/working-with-sources/credible-sources/
[2] Leonard Richardson Revision 546. (2015). Beautiful Soup Documentation. Beautiful Soup. Retrieved May 3, 2024, from https://beautiful-soup-4.readthedocs.io/en/latest/
[3] LinkedIn. (2023, October 19). Web Scraping Author and Affiliation Data for Collaboration Analysis. LinkedIn. Retrieved May 3, 2024, from https://www.linkedin.com/advice/3/how-can-you-extract-author-affiliation-data-from-academic-ksquf
[4] Lofaro, L. (2024). Working With JSON Data in Python – Real Python. Real Python. Retrieved May 3, 2024, from https://realpython.com/python-json/
[5] Mohan, M. (2020, September 25). Web Scraping Python Tutorial – How to Scrape Data From A Website. freeCodeCamp. Retrieved May 3, 2024, from https://www.freecodecamp.org/news/web-scraping-python-tutorial-how-to-scrape-data-from-a-website/